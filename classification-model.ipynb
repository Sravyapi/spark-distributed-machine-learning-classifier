{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Sravya pidugu        #50249282          sravyapi@buffalo.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Citations:\n",
    "\n",
    "    https://spark.apache.org/docs/2.2.0/ml-classification-regression.html\n",
    "    \n",
    "    \n",
    "    https://mapr.com/blog/churn-prediction-pyspark-using-mllib-and-ml-packages/\n",
    "    \n",
    "    \n",
    "    https://spark.apache.org/docs/2.1.0/ml-features.html#tf-idf\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create folders in which we are going to collect article files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3,json,sys,os\n",
    "from bs4 import BeautifulSoup\n",
    "from topstories import TopStoriesAPI\n",
    "import pandas as pd\n",
    "import math\n",
    "import sys, os, re\n",
    "import pandas as pd\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from operator import add\n",
    "\n",
    "urllib3.disable_warnings()\n",
    "os.chdir('/Users/sp/Desktop/LAB3/data-analysis-using-apache-spark')\n",
    "api = TopStoriesAPI('') #set API key\n",
    "topic=['business','politics','sports','opinion']\n",
    "\n",
    "\n",
    "def createdir(newpath):\n",
    "        if not os.path.exists(newpath):\n",
    "            os.makedirs(newpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get article data from NYTimes using get_stories api. Save URLs into CSV and append URLs to that CSV with new URLs \n",
    "everytime you collect data,Remove duplicate URLs before navigating into the URL and parsing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getArticles():\n",
    "    for CurrentTopic in topic: \n",
    "        createdir('./data/'+CurrentTopic)\n",
    "        stories = api.get_stories(CurrentTopic)\n",
    "        urls=[i[\"url\"] for i in (stories)]\n",
    "        URL_File=pd.DataFrame(urls).reset_index(drop=True)\n",
    "        URL_File.to_csv(CurrentTopic+'_url_'+'.csv',mode='a',header=False) \n",
    "        URL= pd.read_csv(CurrentTopic+'_url_'+'.csv').reset_index(drop=True)\n",
    "        url_list= URL.values.T.tolist()\n",
    "        appended_urls=list(set(url_list[1]))\n",
    "        paragraphs = []\n",
    "        for url in appended_urls: #navigate to each URL and collect article data\n",
    "            paragraphs.append(\" \".join([i.text for i in BeautifulSoup(urllib3.connection_from_url(url).urlopen('GET',url).data, \"lxml\").findAll(\"p\") if i.text != \"\" and \"advertisement\" not in i.text.lower()]).replace(\"\\n\",\" \"))    \n",
    "            with open('./data/'+CurrentTopic+ \"/article \"+str(appended_urls.index(url))+\".txt\", \"w\") as text_file: #writing into a textfile\n",
    "                text_file.writelines(paragraphs[appended_urls.index(url)])\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "getArticles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setting variables and creating spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "category = os.listdir(\"data\")\n",
    "category=category[1:5]\n",
    "Data_folders = [\"data\"+\"/\"+i for i in category]\n",
    "TOP_N = 100\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MapReduce using spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lines_list = []\n",
    "for i in range(len(Data_folders)):\n",
    "    lines = sc.textFile(Data_folders[i])\n",
    "    lines_list.append(lines)\n",
    "    \n",
    "    words = lines.flatMap(lambda x: x.split(\" \"))\n",
    "    tuples= words.map(lambda x: (re.sub(r'[^a-zA-Z ]+', '',x).lower(),1))\n",
    "    pairs = tuples.reduceByKey(add).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count=[]\n",
    "\n",
    "for word,count in pairs:\n",
    "    if len(word) > 2 and (word not in stop_words):\n",
    "        word_count.append([word,count])\n",
    "    df = pd.DataFrame(word_count,columns=[\"word\",\"count\"])\n",
    "    Most_freq_words=[]\n",
    "    df = df.sort_values('count',ascending=False)[1:]\n",
    "    Most_freq_words+=(list(df[:TOP_N][\"word\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate probablity of occurrence of each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_generator(words,feature):\n",
    "    prob = float(words.count(feature.lower()))/float(len(words))\n",
    "    if prob != 0.0:\n",
    "        return -1.0/math.log(prob)\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data tokenizing,filtering and getting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(line,features,label):\n",
    "    no_SpecialCharacters = re.sub('[^a-zA-Z ]','',line).lower()\n",
    "    word_tokens = word_tokenize(no_SpecialCharacters)\n",
    "    filtered_sentence = [w for w in word_tokens if w not in stop_words]\n",
    "    TokenizedOutput = ' '.join(filtered_sentence).strip()\n",
    "    words = TokenizedOutput.split()\n",
    "    return [[tf_idf_generator(words,i) for i in features]+[label]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect features from rdd,write it to a CSV and append labels to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in Data_folders:\n",
    "    lines = lines_list[Data_folders.index(i)]\n",
    "    features = lines.flatMap(lambda x: get_features(x,Most_freq_words,i.split(\"/\")[-1].strip().lower()))\n",
    "    feature_set = features.collect()\n",
    "    df = pd.DataFrame(feature_set,columns=Most_freq_words+[\"label\"])\n",
    "    label=category[Data_folders.index(i)]\n",
    "    df.to_csv(label+\"_features_\"+\".csv\",index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append all features into a pandas DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "stored_data=[]\n",
    "for eachSection in category:\n",
    "    with open(eachSection+'_features_'+'.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        lin = [i for i in reader]\n",
    "        df3=pd.DataFrame(lin[1:], columns=lin[0])\n",
    "        stored_data.append(df3)\n",
    "df4=pd.concat(stored_data)\n",
    "df4 = df4.reset_index(drop=True)  #df4 has appended features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert pandas dataframe into spark data frame and then to rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "sparkDF = sqlContext.createDataFrame(df4)\n",
    "sparkRDD = sparkDF.rdd.map(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into 80% training data which will be used to train the model using Cross validation\n",
    "The remaining 20% will be used to test the models  accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_data, testing_data = sparkRDD.randomSplit([0.8, 0.2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ML package needs data be put in a (label: Double, features: Vector) DataFrame format with correspondingly named fields. The vectorizeData() function below performs this formatting.\n",
    "\n",
    "Next we'll pass the data through a pipeline of two transformers, StringIndexer() and VectorIndexer() which index the label and features fields respectively. Indexing categorical features allows decision trees to treat categorical features appropriately, improving performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vectorizeData(data):\n",
    "    return data.map(lambda r: [r[-1], Vectors.dense(r[:-1])]).toDF(['label','features'])\n",
    "\n",
    "vectorized_CV_data = vectorizeData(training_data)\n",
    "vectorized_test_data = vectorizeData(testing_data)\n",
    "\n",
    "# Index labels, adding metadata to the label column\n",
    "labelIndexer = StringIndexer(inputCol='label',outputCol='indexedLabel').fit(vectorized_CV_data)\n",
    "\n",
    "# Automatically identify categorical features and index them\n",
    "featureIndexer = VectorIndexer(inputCol='features',\n",
    "                               outputCol='indexedFeatures',\n",
    "                               maxCategories=2).fit(vectorized_CV_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training decision tree model and performing crossvalidation on it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ML package supports k-fold cross validation, which can be readily coupled with a parameter grid builder and\n",
    "an evaluator to construct a model selection workflow. \n",
    "\n",
    "Below, we'll use a transformation/estimation pipeline to train our models. \n",
    "\n",
    "The cross validator will use the ParamGridBuilder to iterate through the maxDepth parameter of the decision tree and evaluate the models using the F1-score, \n",
    "repeating 3 times per parameter value for reliable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train a DecisionTree model\n",
    "dTree = DecisionTreeClassifier(labelCol='indexedLabel', featuresCol='indexedFeatures')\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline_DT = Pipeline(stages=[labelIndexer, featureIndexer, dTree])\n",
    "\n",
    "# Search through decision tree's maxDepth parameter for best model\n",
    "paramGrid_DT = ParamGridBuilder().addGrid(dTree.maxDepth, [2,3,4,5,6,7]).build()\n",
    "\n",
    "# Set F-1 score as evaluation metric for best model selection\n",
    "evaluator_DT = MulticlassClassificationEvaluator(labelCol='indexedLabel',\n",
    "                                              predictionCol='prediction', metricName='f1')    \n",
    "# Set up 3-fold cross validation\n",
    "crossval_DT = CrossValidator(estimator=pipeline_DT,estimatorParamMaps=paramGrid_DT,\n",
    "                             evaluator=evaluator_DT,numFolds=3)\n",
    "\n",
    "CV_model_DT = crossval_DT.fit(vectorized_CV_data)\n",
    "\n",
    "# Fetch best model\n",
    "tree_model = CV_model_DT.bestModel.stages[2]\n",
    "#print (tree_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final element in our pipeline is an estimator (a decision tree classifier) \n",
    "training on the indexed labels and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7616747049660055\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transformed_data_DT = CV_model_DT.transform(vectorized_test_data)\n",
    "DT_accuracy=evaluator_DT.evaluate(transformed_data)\n",
    "print (evaluator.getMetricName(), DT_accuracy)\n",
    "\n",
    "#predictions_DT = transformed_data_DT.select('indexedLabel', 'prediction', 'probability')\n",
    "\n",
    "#predictions_DT.toPandas().head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a RandomForest model\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=10)\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline_RF = Pipeline(stages=[labelIndexer, featureIndexer, rf])\n",
    "\n",
    "# Search through decision tree's maxDepth parameter for best model\n",
    "paramGrid_RF = ParamGridBuilder().addGrid(rf.maxDepth, [2,3,4,5,6,7]).build()\n",
    "\n",
    "# Set F-1 score as evaluation metric for best model selection\n",
    "evaluator_RF = MulticlassClassificationEvaluator(labelCol='indexedLabel',\n",
    "                                              predictionCol='prediction', metricName='f1')    \n",
    "\n",
    "# Set up 3-fold cross validation\n",
    "crossval_RF = CrossValidator(estimator=pipeline_RF,estimatorParamMaps=paramGrid_RF,\n",
    "                          evaluator=evaluator_RF,\n",
    "                          numFolds=3)\n",
    "\n",
    "CV_model_RF = crossval_RF.fit(vectorized_CV_data)\n",
    "\n",
    "# Fetch best model\n",
    "rf_model = CV_model_RF.bestModel.stages[2]\n",
    "#print (rf_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7652173913043478\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transformed_data_RF = CV_model_RF.transform(vectorized_test_data)\n",
    "RF_accuracy=evaluator.evaluate(transformed_data_RF)\n",
    "print ('accuracy:', RF_accuracy)\n",
    "\n",
    "predictions_rf = transformed_data_RF.select('indexedLabel', 'prediction', 'probability')\n",
    "#predictions_rf.toPandas().head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest is a better model for the given data\n"
     ]
    }
   ],
   "source": [
    "if RF_accuracy>DT_accuracy:\n",
    "    print ('Random forest is a better model for the given data')\n",
    "else:\n",
    "    print ('Decision tree is a better model for the given data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+--------------------+\n",
      "|predictedLabel|  label|            features|\n",
      "+--------------+-------+--------------------+\n",
      "|       opinion|opinion|[0.15173813649584...|\n",
      "|       opinion|opinion|[0.23844845638038...|\n",
      "|       opinion|opinion|[0.20522715403771...|\n",
      "|       opinion|opinion|[0.0,0.0,0.297313...|\n",
      "|       opinion|opinion|[0.0,0.0,0.0,0.33...|\n",
      "+--------------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "accuracy accuracy: 0.7652173913043478\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "# Train a RandomForest model.\n",
    "randomForest = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=10)\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, randomForest, labelConverter])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "modelRF = pipeline.fit(vectorized_CV_data)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = modelRF.transform(vectorized_test_data)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"predictedLabel\", \"label\", \"features\").show(5)\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "##\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, randomForest])\n",
    "\n",
    "# Search through decision tree's maxDepth parameter for best model\n",
    "paramGrid = ParamGridBuilder().addGrid(randomForest.maxDepth, [2,3,4,5,6,7]).addGrid(randomForest.maxBins,[12,23,32,45]).build()\n",
    "# Set up 3-fold cross validation\n",
    "crossval = CrossValidator(estimator=pipeline,estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3)\n",
    "\n",
    "CV_model_RF = crossval.fit(vectorized_CV_data)\n",
    "\n",
    "# Fetch best model\n",
    "RF_model_CV = CV_model_RF.bestModel.stages[2]\n",
    "#print (RF_model_CV)\n",
    "vectorized_test_data = vectorizeData(testing_data)\n",
    "transformed_data = CV_model_RF.transform(vectorized_test_data)\n",
    "print (evaluator.getMetricName(), 'accuracy:', evaluator.evaluate(transformed_data))\n",
    "#rfModel = modelRF.stages[2]\n",
    "#print(rfModel)  # summary only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
